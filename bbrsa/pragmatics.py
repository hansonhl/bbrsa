import torch
import numpy as np
import logging
from bbrsa.abstract_classes import Pragmatics

class BasicPragmatics(Pragmatics):
    def __init__(self, opts, logger=None):
        super().__init__(opts, logger)

    def l1(self, log_probs, opts, *args):
        """Pragmatic listener based on top of s0"""
        normalized = log_probs - torch.logsumexp(log_probs, dim=1, keepdim=True)
        normalized[torch.isnan(normalized)] = -np.log(normalized.shape[1])

        return normalized

    def s1(self, s0_log_probs, l1_log_probs, opts, *args):
        """Pragmatic speaker"""
        likelihood = opts.prag_alpha * l1_log_probs
        likelihood[torch.isnan(likelihood)] = float('-inf')

        log_probs = s0_log_probs + likelihood

        log_probs -=  torch.logsumexp(log_probs, dim=2, keepdim=True)
        return log_probs

    def inference(self, s0_log_probs, opts, *args):
        """Do pragmatic inference based on log probs generated by s0
        Args:
            s0_log_probs: `tensor([*, num_world_states, vocab_size])`
                `num_word_states` is also called `d_factor`
            rem_idxs: only used for memoized listener

        Returns:
            `tensor([*, num_world_states, vocab_size])`
        """
        l1_log_probs = self.l1(s0_log_probs, opts, *args)
        return self.s1(s0_log_probs, l1_log_probs, opts, *args)

class GrowingAlphaPragmatics(BasicPragmatics):
    def __init__(self, opts, logger=None):
        super().__init__(opts, logger)
        self.plusone = (opts.pragmatics == 'growing_alpha_p1')

    def s1(self, s0_log_probs, l1_log_probs, opts, step):
        """Pragmatic speaker, alpha grows incrementally until it reaches self.alpha"""
        grow_steps = opts.prag_alpha_grow_steps
        if step is not None:
            if self.plusone:
                alpha = min(step+1, grow_steps) / grow_steps * opts.prag_alpha
            else:
                alpha = min(step, grow_steps) / grow_steps * opts.prag_alpha

        likelihood = alpha * l1_log_probs
        likelihood[torch.isnan(likelihood)] = float('-inf')
        log_probs = s0_log_probs + likelihood

        normalized = log_probs - torch.logsumexp(log_probs, dim=2, keepdim=True)
        return normalized

class MemoizedListener(BasicPragmatics):
    def __init__(self, opts, logger=None):
        super().__init__(opts, logger)
        self.l1_prev_prob = None

    def clear_mem(self):
        del self.l1_prev_prob
        self.l1_prev_prob = None

    def l1(self, log_probs, opts, rem_idxs, curr_pred):
        """Pragmatic listener that uses prob of previous time step as prior
        Args:
            log_probs: tensor((batch_size * beam_size), d_factor, vocab_size)
            rem_idxs: indices of partial sentences chosen in latest time step,
                tensor((batch_size * beam_size), )
            curr_pred: predicted words for each partial sentence in latest time
                step, tensor((batch_size * beam_size), )
        """
        num_world_states = log_probs.shape[1]
        beam_size = opts.beam_size
        batch_size = log_probs.shape[0] / beam_size

        if self.l1_prev_prob is None:
            self.l1_prev_prob = torch.zeros(log_probs.shape, dtype=torch.float,
                                            device=self.device)
            # self._debug('l1_prev_prob.shape %s' % str(self.l1_prev_prob.shape))
            self.l1_prev_prob -= np.log(num_world_states)
            priors = torch.zeros(log_probs.shape[:-1], dtype=torch.float,
                                 device=self.device)
            priors -= np.log(num_world_states)
            priors = priors.unsqueeze(2)

        if rem_idxs is not None:
            offset = (torch.arange(batch_size, dtype=torch.long, device=self.device) * 10)\
                     .repeat_interleave(beam_size)
            rem_idxs += offset
            # self._debug("rem_idxs.shape %s" % str(rem_idxs.shape))
            #  self._debug("rem_idxs %s" % str(rem_idxs))
            # self._debug("curr_pred.shape %s" % str(curr_pred.shape))

            priors = self.l1_prev_prob.index_select(0, rem_idxs)  # [B*b', d, V]
            # self._debug("priors.shape %s" % str(priors.shape))
            range = torch.arange(priors.shape[0], dtype=torch.long,
                                 device=self.device)
            priors = priors[range, :, curr_pred] # [B*b', d]
            priors = priors - torch.logsumexp(priors, dim=1, keepdim=True)
            priors = priors.unsqueeze(2)   #[B*b', d, 1]

        new_log_probs = log_probs + priors
        normalized = new_log_probs - torch.logsumexp(new_log_probs, dim=1, keepdim=True)
        normalized[torch.isnan(normalized)] = -np.log(num_world_states)
        del self.l1_prev_prob
        self.l1_prev_prob = normalized

        return normalized
