import torch
import numpy as np
import logging
from bbrsa.abstract_classes import BatchDistractor, Pragmatics
from scipy.special import logsumexp


class NextExampleDistractor(BatchDistractor):
    """Use next example in batch as distractor"""
    def __init__(self, batch_size, logger=None):
        super().__init__(batch_size, logger)
        self._d_factor = 2

    @property
    def d_factor(self):
        return self._d_factor

    def generate(self, src):
        new_src = []
        for batch in _chunks(src, self.orig_batch_size):
            for i, x in enumerate(batch):
                new_src.append(x)
                next_id = 0 if i == len(batch) - 1 else i + 1
                new_src.append(batch[next_id])
        return new_src, self.new_batch_size

class IdenticalDistractor(BatchDistractor):
    """Use the sample itself as distractor"""
    def __init__(self, batch_size, logger=None):
        super().__init__(batch_size, logger)
        self._d_factor = 2

    @property
    def d_factor(self):
        return self._d_factor

    def generate(self, src):
        new_src = []
        for x in src:
            new_src.append(x)
            new_src.append(x)
        return new_src, self.new_batch_size

class NextNDistractor(BatchDistractor):
    """Use next N examples in batch as distractor"""
    def __init__(self, batch_size, N, logger=None):
        assert batch_size >= N+1, 'Invalid N!'
        super().__init__(batch_size, logger)
        self._d_factor = N+1

    @property
    def d_factor(self):
        return self._d_factor

    def generate(self, src):
        new_src = []
        for batch in _chunks(src, self.orig_batch_size):
            if len(batch) < self.d_factor:
                self._log('Dropping this batch that is too short', logging.WARNING)
                continue
            for i, x in enumerate(batch):
                ids = [j if j < len(batch) else j - len(batch) \
                    for j in range(i, i + self.d_factor)]
                new_src += [batch[j] for j in ids]

        return new_src, self.new_batch_size


class BasicPragmatics(Pragmatics):
    def __init__(self, alpha=1, logger=None):
        super().__init__(logger)
        self.alpha = alpha

    def l1(self, log_probs, *args):
        """Pragmatic listener based on top of s0"""
        # TODO: consider efficiency of not transposing?
        normalized = log_probs - torch.logsumexp(log_probs, dim=1, keepdim=True)
        normalized[torch.isnan(normalized)] = -np.log(normalized.shape[1])
        # print('has inf?', normalized[torch.isinf(normalized)].shape)

        return normalized

    def s1(self, s0_log_probs, l1_log_probs, *args):
        """Pragmatic speaker"""
        adjusted = self.alpha * l1_log_probs
        isnan_mask = torch.isnan(adjusted)
        adjusted[isnan_mask] = float('-inf')

        log_probs = s0_log_probs + adjusted

        lse = torch.logsumexp(log_probs, dim=2, keepdim=True)
        normalized = log_probs - lse
        return normalized

    def inference(self, s0_log_probs, *args):
        """Do pragmatic inference based on log probs generated by s0
        Args:
            s0_log_probs: tensor([*, num_world_states, vocab_size])
            rem_idxs: only used for memoized listener
        """
        s0_log_probs = s0_log_probs.type(torch.double)
        l1_log_probs = self.l1(s0_log_probs, *args)
        res = self.s1(s0_log_probs, l1_log_probs, *args).type(torch.float)
        return res

class GrowingAlphaPragmatics(BasicPragmatics):
    def __init__(self, alpha=1., steps=5, logger=None):
        super().__init__(alpha, logger)
        # this alpha is used as final alpha
        self.steps = steps

    def s1(self, s0_log_probs, l1_log_probs, step):
        """Pragmatic speake, alpha grows incrementally until it reaches self.alpha"""
        if step is not None:
            alpha = max(step, self.steps) / self.steps * self.alpha # grows in  steps

        adjusted = alpha * l1_log_probs
        isnan_mask = torch.isnan(adjusted)
        adjusted[isnan_mask] = float('-inf')

        log_probs = s0_log_probs + adjusted

        lse = torch.logsumexp(log_probs, dim=2, keepdim=True)
        normalized = log_probs - lse
        return normalized

class MemoizedListener(BasicPragmatics):
    # TODO: Need to fix - l1_prev_prob should have dimension of [B*b, d]
    #    instead of [B*b, d, V]: need to use the output word that's chosen in
    #    last timestep. For this I need to add one more argument in l1.
    #    probably use *args in base definition?
    def __init__(self, alpha=1, logger=None):
        super().__init__(alpha, logger)
        self.l1_prev_prob = None

    def clear_mem(self):
        del self.l1_prev_prob
        self.l1_prev_prob = None

    def l1(self, log_probs, rem_idxs, curr_pred, *args):
        """Pragmatic listener that uses prob of previous time step as prior
        Args:
            log_probs: tensor((batch_size * beam_size), d_factor, vocab_size)
            rem_idxs: indices of partial sentences chosen in latest time step,
                tensor((batch_size * beam_size), )
            curr_pred: predicted words for each partial sentence in latest time
                step, tensor((batch_size * beam_size), )
        """
        num_world_states = log_probs.shape[1]

        if self.l1_prev_prob is None:
            self.l1_prev_prob = torch.zeros(log_probs.shape, dtype=torch.double)
            self.l1_prev_prob -= np.log(num_world_states)
            priors = torch.zeros(log_probs.shape[:-1], dtype=torch.double)
            priors -= np.log(num_world_states)
            priors = priors.unsqueeze(2)

        if rem_idxs is not None:
            priors = self.l1_prev_prob.index_select(0, rem_idxs)      # [B*b', d, V]
            priors = priors[torch.arange(priors.shape[0]), :, curr_pred] # [B*b', d]
            priors = priors - torch.logsumexp(priors, dim=1, keepdim=True)
            priors = priors.unsqueeze(2)                           #[B*b', d, 1]

        new_log_probs = log_probs + priors
        normalized = new_log_probs - torch.logsumexp(new_log_probs, dim=1, keepdim=True)
        normalized[torch.isnan(normalized)] = -np.log(num_world_states)
        self.l1_prev_prob = normalized

        return normalized


def _chunks(l, n):
    """Yield successive n-sized chunks from l."""
    # from https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks
    for i in range(0, len(l), n):
        yield l[i:i + n]
